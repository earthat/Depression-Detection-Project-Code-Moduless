{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CXVj-8n55i8"
      },
      "outputs": [],
      "source": [
        "# main.py\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from gcngru import GRU_Model  # Import GRU_Model from gcngru.py\n",
        "from gtmp import Main_Model  # Import Main_Model from gtmp.py\n",
        "from training_data import TrainingData  # Make sure this is available or adapt as needed\n",
        "\n",
        "# Define the dataset class\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        signal_processed, Adj_dist_matrix, bdi_label = self.data[idx]\n",
        "        return signal_processed, Adj_dist_matrix, bdi_label\n",
        "\n",
        "def load_processed_data(file_path):\n",
        "    return np.load(file_path, allow_pickle=True)\n",
        "\n",
        "def prepare_data(data):\n",
        "    X = TrainingData.trainingData_iterator(data)\n",
        "    return X\n",
        "\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for input_seq, adjacency_matrix, bdi_label in dataloader:\n",
        "        input_seq = input_seq.to(device).float()\n",
        "        adjacency_matrix = adjacency_matrix.to(device).float()\n",
        "        bdi_label = bdi_label.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_seq, adjacency_matrix)\n",
        "        loss = criterion(output, bdi_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Training Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "def main():\n",
        "    # Load processed signals\n",
        "    processed_signals_path = 'processed_signals.npy'\n",
        "    training_data = load_processed_data(processed_signals_path)\n",
        "\n",
        "    # Prepare data for training\n",
        "    data = prepare_data(training_data)\n",
        "    dataset = EEGDataset(data)\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    batch_size = 40\n",
        "    train_test_split_ratio = 0.7\n",
        "    train_size = int(len(dataset) * train_test_split_ratio)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Model, loss function, optimizer\n",
        "    nodes_dim = 16\n",
        "    node_features_dim = 16\n",
        "    hidden_dim = 64\n",
        "    num_layers = 2\n",
        "    dropout_prob = 0.5\n",
        "    seq_len = 100  # Define your sequence length\n",
        "    batch_size = 40\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = Main_Model(nodes_dim, node_features_dim, hidden_dim, num_layers, dropout_prob, seq_len, batch_size).to(device)\n",
        "    criterion = nn.MSELoss()  # Adjust if needed\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        train(model, train_dataloader, criterion, optimizer, device)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for input_seq, adjacency_matrix, bdi_label in test_dataloader:\n",
        "            input_seq = input_seq.to(device).float()\n",
        "            adjacency_matrix = adjacency_matrix.to(device).float()\n",
        "            bdi_label = bdi_label.to(device).float()\n",
        "\n",
        "            output = model(input_seq, adjacency_matrix)\n",
        "            predictions = torch.argmax(output, dim=1)\n",
        "            total_correct += (predictions == bdi_label).sum().item()\n",
        "            total_samples += bdi_label.size(0)\n",
        "\n",
        "    print(f'Test Accuracy: {total_correct / total_samples * 100:.2f}%')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}