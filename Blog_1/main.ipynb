{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU-CCX1AX15N",
        "outputId": "9e3c04d6-0635-4132-b871-686652c10d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7H7KRPibkj5",
        "outputId": "1bdb94e5-a4e8-4217-cea7-ef20d43061e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n",
            "Downloading mne-1.8.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.io\n",
        "import scipy.signal\n",
        "import mne\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from functools import partial\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ],
      "metadata": {
        "id": "HCVgnk0nbnwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from signal_extraction import SignalExtraction\n",
        "import pickle\n",
        "\n",
        "root_path = '/content/drive/MyDrive/'\n",
        "file_path_openneuro = 'EEG/'\n",
        "file_path = root_path + file_path_openneuro\n",
        "\n",
        "start = time.time()\n",
        "ls = SignalExtraction.read_mne_iterator(file_path, None)\n",
        "end = time.time()\n",
        "print(f\"Data extraction time: {end - start}\")\n",
        "\n",
        "# Save the data to a pickle file\n",
        "with open('extracted_signals.pkl', 'wb') as f:\n",
        "    pickle.dump(ls, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FfM7-0WbshH",
        "outputId": "6cb09eaf-70c7-48c3-c73a-e2c1fa855563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-007/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-007/eeg/sub-007_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-010/eeg>>>>>>>\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-115/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-115/eeg/sub-115_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-060/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-060/eeg/sub-060_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-066/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-066/eeg/sub-066_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-111/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-111/eeg/sub-111_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-088/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-088/eeg/sub-088_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-016/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-016/eeg/sub-016_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-092/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-092/eeg/sub-092_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-099/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-099/eeg/sub-099_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-100/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-100/eeg/sub-100_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-108/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-108/eeg/sub-108_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-117/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-117/eeg/sub-117_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-089/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-089/eeg/sub-089_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-122/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-122/eeg/sub-122_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-098/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-098/eeg/sub-098_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-102/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-102/eeg/sub-102_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-113/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-113/eeg/sub-113_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-118/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-118/eeg/sub-118_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-005/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-005/eeg/sub-005_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-009/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-009/eeg/sub-009_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-013/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-013/eeg/sub-013_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-014/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-014/eeg/sub-014_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-018/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-018/eeg/sub-018_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-086/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-086/eeg/sub-086_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-081/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-081/eeg/sub-081_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-085/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-085/eeg/sub-085_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-107/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-107/eeg/sub-107_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-109/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-109/eeg/sub-109_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-112/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-112/eeg/sub-112_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-114/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-114/eeg/sub-114_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-121/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-121/eeg/sub-121_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-120/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-120/eeg/sub-120_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-119/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-119/eeg/sub-119_task-Rest_run-02_eeg.fdt\n",
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-046/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-046/eeg/sub-046_task-Rest_run-02_eeg.fdt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/signal_extraction.py:108: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  mne_obj = mne.io.read_raw_eeglab(mne_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<<<<<<Processing /content/drive/MyDrive/EEG/sub-001/eeg>>>>>>>\n",
            "Reading /content/drive/MyDrive/EEG/sub-001/eeg/sub-001_task-Rest_run-02_eeg.fdt\n",
            "Data extraction time: 172.31960248947144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from signal_processing import SignalProcessing\n",
        "import time\n",
        "\n",
        "# Load extracted signals from the pickle file\n",
        "with open('extracted_signals.pkl', 'rb') as f:\n",
        "    ls = pickle.load(f)\n",
        "\n",
        "sliceSize = 6\n",
        "bandFreqRange = [40, 100]\n",
        "downsampleFreq = 200\n",
        "subSliceSize = 2\n",
        "sampleFrequency = 500\n",
        "\n",
        "start = time.time()\n",
        "training_data, error_data = SignalProcessing.signal_processing_iterator(ls, sampleFrequency, bandFreqRange, downsampleFreq, sliceSize, subSliceSize)\n",
        "end = time.time()\n",
        "print(f\"Signal processing time: {end - start}\")\n",
        "\n",
        "print(f\"Number of training data samples: {len(training_data)}\")\n",
        "\n",
        "# Save processed data for further preparation\n",
        "with open('processed_signals.pkl', 'wb') as f:\n",
        "    pickle.dump(training_data, f)\n",
        "\n",
        "with open('error_signals.pkl', 'wb') as f:\n",
        "    pickle.dump(error_data, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsH2KiPqb4KC",
        "outputId": "4b7b9170-f6a4-4a5b-a70f-4184ef0e63cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Signal processing time: 11.167258977890015\n",
            "Number of training data samples: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from training_data import TrainingData\n",
        "\n",
        "# Load processed signals\n",
        "training_data = np.load('processed_signals.pkl', allow_pickle=True)\n",
        "\n",
        "# Creating a folder to save processed data\n",
        "output_folder = \"processed_data\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Saving processed data for each subject\n",
        "for subject_id, signal_processed, Adj_dist_matrix, bdi, bdi_label in training_data:\n",
        "    subject_folder = os.path.join(output_folder, subject_id)\n",
        "    if not os.path.exists(subject_folder):\n",
        "        os.makedirs(subject_folder)\n",
        "\n",
        "    # Save processed data in the subject's folder\n",
        "    np.save(os.path.join(subject_folder, \"signal_processed.npy\"), signal_processed)\n",
        "    np.save(os.path.join(subject_folder, \"Adj_dist_matrix.npy\"), Adj_dist_matrix)\n",
        "    np.save(os.path.join(subject_folder, \"bdi_label.npy\"), bdi_label)\n",
        "\n",
        "X = TrainingData.trainingData_iterator(training_data)\n",
        "\n",
        "# Distribution of categorical Variable\n",
        "ls = []\n",
        "for i in X:\n",
        "    signal_slice, Adj_dist_matrix, bdi_label = i\n",
        "    ls.append(bdi_label)\n",
        "\n",
        "print(len(ls), sum(ls), len(ls)-sum(ls))\n",
        "\n",
        "dataSet = X\n",
        "print(len(dataSet))\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "def train_test_datasets(dataSet, batch_size, train_test_split):\n",
        "    train_size = int(len(dataSet) * train_test_split)\n",
        "    test_size = len(dataSet) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataSet, [train_size, test_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "batch_size = 40\n",
        "train_test_split = 0.7\n",
        "\n",
        "train_dataloader, test_dataloader = train_test_datasets(dataSet, batch_size, train_test_split)\n",
        "\n",
        "print(len(train_dataloader), len(test_dataloader), len(train_dataloader.dataset) + len(test_dataloader.dataset), (len(train_dataloader)-1)*batch_size + len(test_dataloader))\n",
        "\n",
        "signal, Adj_dist_matrix, label = dataSet[0]\n",
        "print(signal.shape, Adj_dist_matrix.shape, label, len(dataSet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_nkK-8acF_4",
        "outputId": "a3811163-5021-4182-b8d7-b2f54899f3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3268 2357 911\n",
            "3268\n",
            "58 25 3268 2305\n",
            "(3, 16, 400) (16, 16) 0 3268\n"
          ]
        }
      ]
    }
  ]
}